{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Fragrantica perfume review clasifier (LSTM with stopword removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from os import path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Model Name\n",
    "MODEL_NAME = 'lstm_with_stopword_removed_11'\n",
    "\n",
    "# HyperParameters\n",
    "PAD_LEN = 200\n",
    "NUM_WORDS = 1000\n",
    "EMBEDDING = 50\n",
    "BATCH_SIZE = 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_path = '../dataset/dataset_210626_215600.csv'\n",
    "data_exist = path.exists(data_path)\n",
    "\n",
    "if not data_exist:\n",
    "    url = 'https://kyuuuw-nlp-dataset.s3.ap-northeast-2.amazonaws.com/fragrantica/dataset_210626_215600.csv'\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    open(data_path, 'w').write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74779\n",
      "74779\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(data_path)\n",
    "\n",
    "X_data = data['stopwords_removed']\n",
    "y_data = data['label']\n",
    "\n",
    "print(len(X_data))\n",
    "print(len(y_data))\n",
    "\n",
    "\n",
    "##### 토큰화 및 인덱스 부여"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['got', 'sample', 'today', 'year', 'old', 'daughter', 'thought', 'smelling', 'sprayed', 'card', 'rotten', 'fish', 'nearly', 'threw', 'immediately', 'however', 'later', 'evening', 'decided', 'give', 'fair', 'trial', 'sprayed', 'crook', 'elbows', 'rotting', 'fish', 'smell', 'time', 'got', 'definite', 'bit', 'funk', 'almost', 'urine', 'scent', 'minutes', 'blossomed', 'gorgeous', 'smooth', 'woody', 'ambery', 'clean', 'warm', 'jasmine', 'daughter', 'didnt', 'even', 'believe', 'told', 'fragrance', 'smelled', 'earlier', 'lol', 'immediately', 'commented', 'fresh', 'clean', 'vibe', 'agree', 'soapy', 'hint', 'powdery', 'way', 'obsessed', 'cant', 'stop', 'smelling', 'arm', 'glad', 'gave', 'try', 'wait', 'buy', 'full', 'bottle']\n",
      "76\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_data)\n",
    "sequences = tokenizer.texts_to_sequences(X_data)\n",
    "\n",
    "print(X_data[0])\n",
    "print(len(sequences[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### 인덱스별 단어 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "word_to_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### 빈도수 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "등장 빈도가 2번 이하인 희귀 단어의 수: 44912\n",
      "단어 집합(vocabulary)에서 희귀 단어의 비율: 0.552307635549762\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 0.013189565348140857\n"
     ]
    }
   ],
   "source": [
    "threshold = 2\n",
    "total_cnt = len(word_to_index) # 총 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도 수가 threshold 보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0\n",
    "\n",
    "for key, value in tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    if value < threshold:\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print(f\"등장 빈도가 {threshold}번 이하인 희귀 단어의 수: {rare_cnt}\")\n",
    "print(f\"단어 집합(vocabulary)에서 희귀 단어의 비율: {rare_cnt / total_cnt}\" )\n",
    "print(f\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율: {rare_freq / total_freq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### 등장 횟수 상위 50000개의 word 만 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41, 102, 175, 207, 142, 134, 83, 145, 874, 466, 105, 190, 474, 404, 111, 145, 5, 17, 41, 38, 77, 2, 184, 249, 355, 129, 120, 70, 155, 646, 27, 273, 587, 4, 45, 333, 466, 39, 120, 198, 330, 533, 276, 170, 36, 343, 421, 83, 575, 477, 324, 60, 532, 43, 185, 12], [15, 310, 642, 8, 1, 55, 1, 7, 806, 496, 161, 16, 8, 689, 57, 100, 67, 25, 161, 37, 801, 16, 168, 16, 343, 494, 7, 47, 90, 849, 12, 838, 404, 111, 60, 145, 273, 428, 215, 115, 57, 7, 155, 810, 35, 20, 350, 5, 5, 155, 70, 139, 442, 36, 20, 228, 572, 52, 11, 689, 459, 82, 73, 248, 632, 273, 67, 444, 138, 4, 405, 22, 8, 100, 19, 33, 244, 213, 101, 686, 16, 16, 252, 228, 22, 115, 46, 19, 12, 331, 6, 331, 187, 224, 621, 43, 12, 236, 17, 310, 268, 11], [7, 132, 58, 385, 133, 7, 132, 47, 26, 9, 454, 41, 102, 375, 510, 109, 85, 248, 234, 732, 601, 212, 4, 18, 155, 171, 416, 944, 212], [340, 985, 525, 15, 155, 185, 15, 29, 5, 823, 369, 279, 155, 459, 892, 53, 17, 154, 117, 212, 119, 155, 399, 624, 66, 132, 79, 14, 6, 1, 3, 19, 191, 875, 210, 49, 45, 76, 163, 995, 379, 38, 345, 164, 603, 647, 23, 661, 15, 55, 774, 226, 86, 86, 9, 50, 196, 88, 983, 6, 417, 133, 212, 18, 105, 171, 416, 320, 5, 20, 1, 212, 80], [249, 249, 397, 6, 2, 294, 2, 142, 181, 33, 169, 43, 1, 69, 65, 43]]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=NUM_WORDS)\n",
    "tokenizer.fit_on_texts(X_data)\n",
    "sequences = tokenizer.texts_to_sequences(X_data)\n",
    "\n",
    "print(sequences[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56084\n",
      "56084\n",
      "18695\n",
      "18695\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(sequences, y_data)\n",
    "print(len(X_train))\n",
    "print(len(y_train))\n",
    "print(len(X_test))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 33, 917, 469, 86, 53, 14, 400, 24, 61, 924, 51, 4, 791, 311, 97, 39, 136, 9, 126, 47, 26, 51, 350, 91, 2, 47, 18, 167, 167]\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# padding and trimming\n",
    "X_train = pad_sequences(X_train, maxlen=PAD_LEN)\n",
    "X_test = pad_sequences(X_test, maxlen=PAD_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# One hot encoding\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-06-26 19:55:12.955 tensorflow-2-3-gpu--ml-g4dn-xlarge-794be025f5602a375b1b7feb8a0a:3375 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2021-06-26 19:55:12.980 tensorflow-2-3-gpu--ml-g4dn-xlarge-794be025f5602a375b1b7feb8a0a:3375 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 50)          50000     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 204       \n",
      "=================================================================\n",
      "Total params: 70,404\n",
      "Trainable params: 70,404\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(NUM_WORDS, EMBEDDING))\n",
    "model.add(LSTM(EMBEDDING))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint(f'../model/{MODEL_NAME}.h5', monitor='val_acc', mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "220/220 [==============================] - 5s 21ms/step - loss: 1.1094 - acc: 0.5221 - val_loss: 0.9156 - val_acc: 0.6421\n",
      "Epoch 2/30\n",
      "220/220 [==============================] - 4s 19ms/step - loss: 0.8407 - acc: 0.6737 - val_loss: 0.8022 - val_acc: 0.6899\n",
      "Epoch 3/30\n",
      "220/220 [==============================] - 4s 19ms/step - loss: 0.7688 - acc: 0.7032 - val_loss: 0.8062 - val_acc: 0.6865\n",
      "Epoch 4/30\n",
      "220/220 [==============================] - 4s 19ms/step - loss: 0.7443 - acc: 0.7088 - val_loss: 0.7710 - val_acc: 0.6978\n",
      "Epoch 5/30\n",
      "220/220 [==============================] - 4s 19ms/step - loss: 0.7313 - acc: 0.7146 - val_loss: 0.7734 - val_acc: 0.6956\n",
      "Epoch 6/30\n",
      "220/220 [==============================] - 4s 19ms/step - loss: 0.7249 - acc: 0.7157 - val_loss: 0.7709 - val_acc: 0.6956\n",
      "Epoch 7/30\n",
      "220/220 [==============================] - 4s 19ms/step - loss: 0.7180 - acc: 0.7160 - val_loss: 0.7684 - val_acc: 0.6953\n",
      "Epoch 8/30\n",
      "220/220 [==============================] - 4s 19ms/step - loss: 0.7129 - acc: 0.7191 - val_loss: 0.7610 - val_acc: 0.7000\n",
      "Epoch 9/30\n",
      "220/220 [==============================] - 4s 19ms/step - loss: 0.7105 - acc: 0.7193 - val_loss: 0.7699 - val_acc: 0.6953\n",
      "Epoch 10/30\n",
      "220/220 [==============================] - 4s 19ms/step - loss: 0.7029 - acc: 0.7222 - val_loss: 0.7673 - val_acc: 0.6971\n",
      "Epoch 11/30\n",
      "220/220 [==============================] - 4s 19ms/step - loss: 0.6989 - acc: 0.7230 - val_loss: 0.7613 - val_acc: 0.7009\n",
      "Epoch 12/30\n",
      "220/220 [==============================] - 4s 19ms/step - loss: 0.6921 - acc: 0.7251 - val_loss: 0.7674 - val_acc: 0.6986\n",
      "Epoch 00012: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=BATCH_SIZE, epochs=30, callbacks=[es, mc],\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.3 Python 3.7 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-northeast-2:806072073708:image/tensorflow-2.3-gpu-py37-cu110-ubuntu18.04-v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
